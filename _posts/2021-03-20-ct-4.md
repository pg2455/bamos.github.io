---
layout: distillPost
title:  Deep learning for the framework
date:   2021-03-20 00:00:04
description: Contact tracing as a personalization framework
series:
 name: ct
 id: 4


_styles: >
  h3 {
    padding-top: 0!important;
  }


distill: true
mathjax: true
bibliography: ct.bib

summary: >
  <ul>
    <li><em>A generative model can be used to collect data to train a deep learning based predictor</em></li>
  </ul>

comments: true
---

In the previous post, we discussed various rule-based predictor-recommender pairs for the PCT framework.
These rules are designed by domain experts, who continually update their understanding of the disease, and accordingly rules,  based on the observed data (Figure 4A).
This post explores a machine learning (ML) based methodology that can be useful alongside domain experts.

<div class="row mt-3" markdown="0">
  <div class="col mt-3 mt-md-0">
    <img class="img-fluid rounded z-depth-1" src="/images/blog/ct/step1.png">
  </div>
	<div class="caption" markdown="0">
		<strong>Figure 4A</strong>: <a href="/blog/2021/ct-3/">Previously discussed</a> rule-based predictor-recommender pairs are designed by domain experts, who themselves learn from the real world observations.
	</div>
</div>

As illustrated in Figure 4B, domain experts use their knowledge to build an approximate generative model (also referred to as a simulator) of an epidemic, and the simulator's data is, further, used to train the machine learning models.
This simulator is a crude approximation of how the virus spreads through interactions (i.e., who meets whom) in a synthetic population, which is sampled from the census to resemble a particular demographics.
The interactions between synthetic agents (or software individuals) accounts for the mobility patterns and empirically surveyed contact matrices<d-cite key="Prem2017ProjectingSC"></d-cite>.
Such agent-based models are often used in epidemiology to study the effects of various interventions<d-cite key="ferretti2020quantifying"></d-cite><d-cite key="ferguson2020report"></d-cite>.

<div class="row mt-3" markdown="0">
  <div class="col mt-3 mt-md-0">
    <img class="img-fluid rounded z-depth-1" src="/images/blog/ct/step2.png">
  </div>
	<div class="caption" markdown="0">
		<strong>Figure 4B</strong>: A generative model built with the help of domain experts can be used to collect data to train the machine learning model. Note that there are several realizations of the simulated world to make the model robust to crude assumptions required to build a generative model.
	</div>
</div>

### Deep Learning for PCT
In Bengio et al.<d-cite key="bengio2020predicting"></d-cite>, an agent-based model, <a href="https://github.com/mila-iqia/COVI-AgentSim">COVI-AgentSim</a><d-cite key="gupta2020covi"></d-cite>, is used to collect data to train a machine learning predictor-recommender pair for the PCT framework.
For brevity, we will restrict our discussion in this post to the high-level ideas that were crucial to design a deep learning predictor-recommender pair for the PCT framework.

In Bengio et al.<d-cite key="bengio2020predicting"></d-cite>, we used the simulator to collect observations for each app-user (randomly selected in a population according to age-based smartphone adoption; see section 3.7 of Gupta et al.<d-cite key="gupta2020covi"></d-cite>).
These observations comprise (a) (user-dependent inputs) personal information like pre-existing conditions, daily symptoms, test results, and (b) warning signals received for previous encounters.
The simulator models imperfect user-behavior by using Bernoulli variables for (a).
Through the simulator, we also have access to the underlying ground-truth viral load for each user.
Thus, our objective is to estimate app-users' viral load for the current day and the past 14 days using personal information (if logged), daily symptoms for the past 14 days (if logged), test results (if logged and verified), and warning signals received in the past 14 days.
A non-zero viral load for the current day will trigger a notification to the app-user recommending cautionary behaviors.

Below are some of the key elements of our trained predictor
<ul>
<li><strong>Deep Learning Architecture</strong>: -  Inputs are treading in the following manner
<ul>
<li> daily information about symptoms and test results is aggregated into a single vector for each day (<em>daily health status</em>)</li>
<li>daily warning signals are aggregated to yield a vector with each dimension representing intensities and the value as the number of such warning signals received</li>
<li>an offset element denoting a particular day relative to the current day is concatenated to the above vectors</li>
<li>a vector of personal attributes is used as a separate input</li>
</ul>
These inputs are then processed by a Deep Set<d-cite key="zaheer2017deep"></d-cite> or Set Transformer<d-cite key="lee2018set"></d-cite> type architecture to output a vector of 15 scalars (viral load estimate for the current and the past 14 days).</li>

<li><strong>Domain randomization</strong>: Many crude assumptions go into building such a simulator.
Some examples include the dependence of symptoms on the disease phase, grouping of synthetic agents for interactions, or individual viral load curves.
Thus, a single choice of parameters for a simulator is unlikely to reflect reality.
To make the predictor robust to these assumptions, we employ domain randomization<d-cite key="tobin2017domain"></d-cite> over the parameters fueling these assumptions.
The model, therefore, learns from several alternative worlds realized by randomly sampling these parameters.</li>

<li><strong>Iterative training</strong>: Employing this predictor in the simulator (or even the real world) is likely to result in distribution shifts, i.e., eventually, observations will not be representative of those that were used to train the model.
For example, a predictor <em>P<sub>0</sub></em> trained on the dataset <em>D<sub>0</sub></em>, when used in the simulator, will, eventually, encounter observations not representative of <em>D<sub>0</sub></em>.
To counter this problem, we use iterative training so that a predictor <em>P<sub>n</sub></em> is used in the simulator to collect new dataset <em>D<sub>n+1</sub></em>, which is then used to train a new predictor <em>P<sub>n+1</sub></em>.
We used <em>n = 3</em> in our experiments.</li>

</ul>

### Simulation Results

<a href="/blog/2021/ct-2/#demands-on-the-framework">Recall from our discussion</a> that we, ideally,  want an oracle that accurately predicts an individual's viral load to control the outbreak with minimum economic disruption.
Thus, the results in Bengio et al.<d-cite key="bengio2020predicting"></d-cite> compare this <a href="/blog/2021/ct-1/#trade-off">tradeoff between health and economy</a>.
Specifically, <a href="">BTT</a> (referred by BCT in the paper), a mature heuristic proposed in Gupta et al.<d-cite key="gupta2020covi"></d-cite> (referred by Heuristic), and the above deep learning predictor (referred by DS-PCT or ST-PCT depending on the implementation) are pitted against each other.
Figure 3 in Bengio et al.<d-cite key="bengio2020predicting"></d-cite> compares how each of the above methods negotiate the trade-off.
We consider <em>reproductive number</em> of the disease as the proxy for health, and <em>number of contacts allowed</em> as a proxy for the economy.
Each line in the figure is a <em>Gaussian Parametric (GP)</em> regression fit on simulations ran under varying parameters, thereby yielding a model for each method.
The results suggest a better trade-off exhibited by any contact tracing framework, though PCT improves further upon BTT.


Thus, we argue that the PCT framework is essentially a personalization framework that can improve the existing contact tracing methods.
However, some limitations need to be addressed to harness the full potential of this framework.
We discuss these in our next post.
